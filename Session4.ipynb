{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e7cb5f-2e37-4664-bff2-735b09da2cba",
   "metadata": {},
   "source": [
    "# PROGRAMA DE INTELIGENCIA ARTIFICIAL | IBM SkillUp 2024\n",
    "\n",
    "<!-- Tabla con tres logos -->\n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td><img src=\"https://thepearlhighschool.org/wp-content/uploads/2023/07/rsw_1280-1024x767.webp\" alt=\"IBM\" width=\"350\"></td>\n",
    "        <td><img src=\"https://uptec.up.pt/wp-content/uploads/2022/04/SkillUp_x2.png\" alt=\"Skillup\" width=\"350\"></td>\n",
    "        <td><img src=\"https://visionyvalor.es/wp-content/uploads/2024/03/Python-Symbol_0-3.png\" alt=\"Python\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61eba8-0d81-4bc2-8373-bb692a5e4c0b",
   "metadata": {},
   "source": [
    "## Introducción a la práctica: creación de un Chatbot Inteligente con Voz\n",
    "\n",
    "### Objetivo\n",
    "- En esta práctica, aprenderemos a construir un chatbot avanzado que puede interactuar con los usuarios mediante voz y texto. Utilizaremos diversas tecnologías para lograr un chatbot funcional.\n",
    "\n",
    "#### Los objetivos específicos de esta práctica son:\n",
    "\n",
    "- Integrar la conversión de voz a texto utilizando IBM Watson Speech to Text, para que el chatbot pueda entender las entradas de voz de los usuarios.\n",
    "- Desarrollar un modelo de chatbot inteligente utilizando OpenAI GPT-3, para que el chatbot pueda entender las consultas de los usuarios y generar respuestas coherentes y naturales.\n",
    "- Integrar la conversión de texto a voz utilizando IBM Watson Text to Speech, para que el chatbot pueda responder a los usuarios con salida de audio.\n",
    "- Crear una interfaz web interactiva utilizando Flask, HTML, CSS y JavaScript, permitiendo a los usuarios interactuar con el chatbot de manera intuitiva.\n",
    "\n",
    "  \n",
    "#### Tecnologías que usaremos:\n",
    "- Python y Flask: Para desarrollar el backend de la aplicación web.\n",
    "- IBM Watson Speech to Text: Para convertir la voz del usuario en texto.\n",
    "- OpenAI GPT-3.5: Para generar respuestas inteligentes a partir del texto de entrada.\n",
    "- IBM Watson Text to Speech: Para convertir las respuestas de texto del chatbot en audio.\n",
    "- HTML, CSS y JavaScript: Para crear la interfaz web que los usuarios utilizarán para interactuar con el chatbot.\n",
    "\n",
    "### Descripción del Proyecto\n",
    "\n",
    "El proyecto consiste en un chatbot que puede recibir entradas de voz y texto del usuario, procesar esas entradas para generar una respuesta inteligente, y devolver la respuesta al usuario tanto en texto como en audio. La aplicación tendrá la siguiente funcionalidad:\n",
    "\n",
    "- Entrada de Voz: Los usuarios pueden hablarle al chatbot y el audio será convertido a texto utilizando IBM Watson Speech to Text.\n",
    "- Procesamiento de Texto: El texto generado será enviado a un modelo GPT-3 de OpenAI, que procesará la entrada y generará una respuesta adecuada.\n",
    "- Salida de Voz: La respuesta de texto del chatbot será convertida a audio utilizando IBM Watson Text to Speech y reproducida para el usuario.\n",
    "- Interfaz Web: La aplicación web permitirá a los usuarios interactuar con el chatbot de manera fácil e intuitiva. La interfaz incluirá campos para entrada de texto y botones para grabar y enviar audio.\n",
    "\n",
    "\n",
    "#### Estructura del Proyecto\n",
    "\n",
    "- ***Backend (Python y Flask)***:\n",
    "    - Configuración del servidor Flask.\n",
    "    - Rutas para manejar las peticiones de transcripción de audio, generación de respuestas y conversión de texto a audio.\n",
    "    - Integración con las APIs de IBM Watson y OpenAI.\n",
    "    - Frontend (HTML, CSS y JavaScript):\n",
    "\n",
    "- ***Diseño de la interfaz de usuario utilizando HTML y CSS.***\n",
    "    - Implementación de la lógica de interacción utilizando JavaScript para manejar la grabación de audio, envío de peticiones al servidor y reproducción de respuestas en audio.\n",
    "\n",
    "#### Pasos para Realizar la Práctica\n",
    "- ***Configuración del Entorno:***\n",
    "    - Instalación de las bibliotecas necesarias.\n",
    "    - Configuración de las credenciales para IBM Watson y OpenAI.\n",
    "\n",
    "- ***Desarrollo del Backend:***\n",
    "    - Creación del servidor Flask.\n",
    "    - Implementación de las rutas necesarias para manejar las funcionalidades del chatbot.\n",
    "\n",
    "- ***Desarrollo del Frontend:***\n",
    "    - Diseño de la página web para la interacción con el chatbot.\n",
    "    - Implementación de la lógica para manejar las entradas de voz y texto.\n",
    "\n",
    "- ***Fase de pruebas:***\n",
    "    - Pruebas funcionales del chatbot.\n",
    "\n",
    "### Recursos\n",
    "- Documentación de IBM Watson: Speech to Text, Text to Speech\n",
    "    - https://www.ibm.com/mx-es/products/speech-to-text\n",
    "    - https://www.ibm.com/es-es/products/text-to-speech\n",
    "- Documentación de OpenAI GPT-3: OpenAI API\n",
    "    - https://platform.openai.com/docs/api-reference/authentication\n",
    "- Flask Documentation: Flask\n",
    "    - https://flask-es.readthedocs.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293dc17-025f-465d-9353-1907754fbe83",
   "metadata": {},
   "source": [
    "#### Paso 1: configuración del entorno\n",
    "- Instalamos las librerías de Flask, Openai e IBM-Watson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99906996-f497-489b-85cd-46b8eaf68757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (2.2.5)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.0->flask) (2.1.3)\n",
      "Requirement already satisfied: ibm-watson in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (8.1.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-watson) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-watson) (2.8.2)\n",
      "Requirement already satisfied: websocket-client>=1.1.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-watson) (1.8.0)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core==3.*,>=3.3.6 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-watson) (3.20.3)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=2.1.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm-watson) (2.2.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm-watson) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.5.3->ibm-watson) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson) (2024.2.2)\n",
      "Requirement already satisfied: openai in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from openai) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.9.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/hrg/Applications/Anaconda3/anaconda3/lib/python3.11/site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install ibm-watson\n",
    "!pip install openai\n",
    "!pip install python-dotenv #cargar variables entorno (encapsular API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b276f7c-acbf-4a02-8d30-a430e92ba092",
   "metadata": {},
   "source": [
    "#### Paso 2: configurar el entorno Flask (Backend)\n",
    "- Creamos el archivo chatbot.py\n",
    "- Importamos la librerías necesarias\n",
    "- Creamos el código que nos permitirá acceder a las API´s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5736e938-a76e-4f28-bbdc-7e49d7944b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatbot.py\n",
    "\n",
    "# Importar las bibliotecas necesarias\n",
    "from flask import Flask, render_template, request, jsonify, send_file, render_template_string\n",
    "from ibm_watson import SpeechToTextV1, TextToSpeechV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO  # Importación de BytesIO para manejar datos binarios en memoria\n",
    "import os\n",
    "\n",
    "# Cargar variables de entorno (claves API) desde el archivo .env\n",
    "load_dotenv('claves.env')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Credenciales de IBM Watson Speech to Text\n",
    "stt_authenticator = IAMAuthenticator(os.getenv('SPEECH_TO_TEXT_APIKEY'))\n",
    "speech_to_text = SpeechToTextV1(authenticator=stt_authenticator)\n",
    "speech_to_text.set_service_url(os.getenv('SPEECH_TO_TEXT_URL'))\n",
    "\n",
    "# Credenciales de IBM Watson Text to Speech\n",
    "tts_authenticator = IAMAuthenticator(os.getenv('TEXT_TO_SPEECH_APIKEY'))\n",
    "text_to_speech = TextToSpeechV1(authenticator=tts_authenticator)\n",
    "text_to_speech.set_service_url(os.getenv('TEXT_TO_SPEECH_URL'))\n",
    "\n",
    "# Credenciales de OpenAI\n",
    "#client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    # Ruta para la página principal\n",
    "    # Renderiza el archivo index.html ubicado en el directorio templates\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe():\n",
    "    # ruta para manejar la transcripcion de audio a texto\n",
    "    # Recibe un archivo de audio a través de una solicitud POST\n",
    "    audio = request.files['audio']\n",
    "    # Utiliza el servicio Speech to Text de IBM Watson para reconocer el audio\n",
    "    stt_result = speech_to_text.recognize(\n",
    "        audio=audio, # El archivo de audio recibido\n",
    "        content_type='audio/wav', # Tipo de contenido del archivo de audio\n",
    "        model='es-ES_BroadbandModel' # Modelo de idioma utilizado para la transcripción\n",
    "    ).get_result()\n",
    "\n",
    "    # Extrae el texto transcrito del resultado de la API\n",
    "    transcript = stt_result['results'][0]['alternatives'][0]['transcript']\n",
    "\n",
    "    # Devuelve el texto transcrito en formato JSON\n",
    "    return jsonify({'transcript': transcript})\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    # Ruta para manejar las solicitudes de chat\n",
    "    # Recibe un mensaje de usuario a través de una solicitud POST\n",
    "    user_input = request.json['message']\n",
    "\n",
    "    # Mensaje de depuración para verificar la entrada del usuario\n",
    "    print(\"Mensaje del usuario:\", user_input)\n",
    "\n",
    "    # Utiliza el servicio de OpenAI para generar una respuesta\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Modelo de GPT-3.5 Turbo utilizado para generar la respuesta\n",
    "            messages=[{\"role\": \"user\", \"content\": user_input}]  # Mensaje del usuario en formato de chat\n",
    "        )\n",
    "\n",
    "        # Mensaje de depuración para verificar la respuesta de OpenAI\n",
    "        print(\"Respuesta de OpenAI:\", response.choices[0].message['content'].strip())\n",
    "\n",
    "        # Devuelve la respuesta generada en formato JSON\n",
    "        return jsonify({'response': response.choices[0].message['content'].strip()})\n",
    "    except Exception as e:\n",
    "        print(\"Error al generar la respuesta de OpenAI:\", e)\n",
    "        return jsonify({'response': 'Lo siento, no puedo procesar tu solicitud en este momento.'})\n",
    "\n",
    "@app.route('/speak', methods=['POST'])\n",
    "def speak():\n",
    "    # Ruta para manejar la conversión de texto a voz\n",
    "    # Recibe un texto a través de una solicitud POST\n",
    "    text = request.json['text']\n",
    "    \n",
    "    # Mensaje de depuración para verificar el texto recibido\n",
    "    print(\"Texto recibido para sintetizar:\", text)\n",
    "    \n",
    "    # Utiliza el servicio Text to Speech de IBM Watson para sintetizar el texto\n",
    "    try:\n",
    "        tts_result = text_to_speech.synthesize(\n",
    "            text,  # El texto recibido\n",
    "            voice='es-ES_LauraV3Voice',  # Voz utilizada para la síntesis\n",
    "            accept='audio/wav'  # Tipo de contenido de la respuesta (archivo de audio OGG) \n",
    "        ).get_result()\n",
    "        \n",
    "        # Extrae el contenido de audio de la respuesta de la API\n",
    "        audio = tts_result.content\n",
    "\n",
    "        # Mensaje de depuración para verificar la longitud del audio\n",
    "        print(\"Audio generado, longitud:\", len(audio))\n",
    "        \n",
    "        # Devuelve el contenido de audio como respuesta\n",
    "        return send_file(BytesIO(audio), mimetype='audio/wav')\n",
    "    except Exception as e:\n",
    "        print(\"Error al generar el audio:\", e)\n",
    "        return jsonify({'response': 'Lo siento, no puedo procesar tu solicitud en este momento.'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Inicia la aplicación Flask en modo de depuración\n",
    "    app.run(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fed28-17be-462c-86f4-97aefbea01c2",
   "metadata": {},
   "source": [
    "#### Paso 3: Crear la interfaz de usuario en HTML, CSS y JavaScript (Frontend)\n",
    "- Creamos el archivo index.html:\n",
    "- Creamos el fronted (parte visual) que nos permitirá ejecutar nuestra app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a08860-d97e-4c1d-b825-f3a84e4019c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Crear el directorio templates si no existe\n",
    "os.makedirs(\"templates\", exist_ok=True)\n",
    "\n",
    "# Crea y escribe el archivo index.html dentro del directorio templates\n",
    "with open(\"templates/index.html\", \"w\") as file:\n",
    "    file.write(\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Chatbot con voz</title>\n",
    "    <style>\n",
    "        /* Estilos generales para el cuerpo del documento */\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            height: 100vh;\n",
    "            background-color: #f0f0f0;\n",
    "        }\n",
    "        /* Contenedor principal */\n",
    "        #container {\n",
    "            text-align: center;\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "            border-radius: 10px;\n",
    "        }\n",
    "        /* Caja de chat */\n",
    "        #chat {\n",
    "            border: 1px solid #ccc;\n",
    "            padding: 10px;\n",
    "            height: 300px;\n",
    "            width: 400px;\n",
    "            overflow-y: auto;\n",
    "            margin-bottom: 10px;\n",
    "            background-color: #fff;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        /* Campo de entrada de texto */\n",
    "        #input {\n",
    "            width: calc(100% - 20px);\n",
    "            padding: 10px;\n",
    "            margin-bottom: 10px;\n",
    "            border: 1px solid #ccc;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        /* Botones de enviar y hablar */\n",
    "        #send, #voice {\n",
    "            padding: 10px 20px;\n",
    "            margin: 5px;\n",
    "            border: none;\n",
    "            border-radius: 5px;\n",
    "            background-color: #007BFF;\n",
    "            color: white;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        /* Estilo hover para los botones */\n",
    "        #send:hover, #voice:hover {\n",
    "            background-color: #0056b3;\n",
    "        }\n",
    "        /* Control de audio */\n",
    "        #audio {\n",
    "            margin-top: 10px;\n",
    "            width: 100%;\n",
    "        }\n",
    "        /* Indicador de grabación */\n",
    "        #recording-indicator {\n",
    "            color: red;\n",
    "            display: none;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"container\">\n",
    "        <!-- Contenedor del chat y controles -->\n",
    "        <div id=\"chat\"></div>\n",
    "        <input type=\"text\" id=\"input\" placeholder=\"Escribe tu mensaje\">\n",
    "        <button id=\"send\">Enviar</button>\n",
    "        <button id=\"voice\">Hablar</button>\n",
    "        <p id=\"recording-indicator\">Grabando...</p>\n",
    "        <audio id=\"audio\" style=\"display: none;\"></audio>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        // Referencias a los elementos del DOM\n",
    "        const chat = document.getElementById('chat');\n",
    "        const input = document.getElementById('input');\n",
    "        const send = document.getElementById('send');\n",
    "        const voice = document.getElementById('voice');\n",
    "        const audio = document.getElementById('audio');\n",
    "        const recordingIndicator = document.getElementById('recording-indicator');\n",
    "\n",
    "        // Evento click para el botón de enviar\n",
    "        send.addEventListener('click', () => {\n",
    "            const message = input.value;\n",
    "            if (message.trim() === '') return; // No enviar mensajes vacíos\n",
    "            input.value = '';\n",
    "            chat.innerHTML += `<p><strong>Tú:</strong> ${message}</p>`;\n",
    "            chat.scrollTop = chat.scrollHeight; // Desplazar hacia abajo\n",
    "            fetch('/chat', {\n",
    "                method: 'POST',\n",
    "                headers: { 'Content-Type': 'application/json' },\n",
    "                body: JSON.stringify({ message: message })\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => {\n",
    "                chat.innerHTML += `<p><strong>Bot:</strong> ${data.response}</p>`;\n",
    "                chat.scrollTop = chat.scrollHeight; // Desplazar hacia abajo\n",
    "                fetch('/speak', {\n",
    "                    method: 'POST',\n",
    "                    headers: { 'Content-Type': 'application/json' },\n",
    "                    body: JSON.stringify({ text: data.response })\n",
    "                })\n",
    "                .then(response => response.blob())\n",
    "                .then(blob => {\n",
    "                    const url = URL.createObjectURL(blob);\n",
    "                    audio.src = url;\n",
    "                    audio.play(); // Reproducir el audio\n",
    "                });\n",
    "            });\n",
    "        });\n",
    "\n",
    "        // Evento click para el botón de hablar\n",
    "        voice.addEventListener('click', () => {\n",
    "            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n",
    "            recognition.lang = 'es-ES'; // Idioma de reconocimiento\n",
    "            recognition.start();\n",
    "            recordingIndicator.style.display = 'block'; // Mostrar indicador de grabación\n",
    "            recognition.onresult = (event) => {\n",
    "                const transcript = event.results[0][0].transcript;\n",
    "                input.value = transcript;\n",
    "                send.click(); // Simular el click en el botón de enviar\n",
    "            };\n",
    "            recognition.onend = () => {\n",
    "                recordingIndicator.style.display = 'none'; // Ocultar indicador de grabación\n",
    "            };\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06f3f8-be70-4d95-8370-e5a7c81f4a99",
   "metadata": {},
   "source": [
    "#### Paso 4: Ejecutar la aplicación\n",
    "- Ejecuta el chatbot Flask desde Jupyter Notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70448c-e62c-4e32-89ba-a81db31254a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'chatbot'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with watchdog (fsevents)\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 332-424-502\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:12] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:12] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:12] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "Mensaje del usuario: Hola\n",
      "Respuesta de OpenAI: ¡Hola! ¿Cómo puedo ayudarte hoy?\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:17] \"POST /chat HTTP/1.1\" 200 -\n",
      "Texto recibido para sintetizar: ¡Hola! ¿Cómo puedo ayudarte hoy?\n",
      "Audio generado, longitud: 118438\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:18] \"POST /speak HTTP/1.1\" 200 -\n",
      "Mensaje del usuario: Cómo te encuentras\n",
      "Respuesta de OpenAI: ¡Hola! Soy un asistente de inteligencia artificial, así que no tengo emociones o sentimientos. ¿En qué puedo ayudarte hoy?\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:38] \"POST /chat HTTP/1.1\" 200 -\n",
      "Texto recibido para sintetizar: ¡Hola! Soy un asistente de inteligencia artificial, así que no tengo emociones o sentimientos. ¿En qué puedo ayudarte hoy?\n",
      "Audio generado, longitud: 400038\n",
      "127.0.0.1 - - [16/Jul/2024 06:35:42] \"POST /speak HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!python chatbot.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61529a7b-b6f0-4224-a86d-703e78b6ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
