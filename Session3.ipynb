{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e7cb5f-2e37-4664-bff2-735b09da2cba",
   "metadata": {},
   "source": [
    "# PROGRAMA DE INTELIGENCIA ARTIFICIAL | IBM SkillUp 2024\n",
    "\n",
    "<!-- Tabla con tres logos -->\n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td><img src=\"images/ibm.jpg\" alt=\"IBM\" width=\"350\"></td>\n",
    "        <td><img src=\"images/skillup.jpeg\" alt=\"Skillup\" width=\"350\"></td>\n",
    "        <td><img src=\"images/python.jpeg\" alt=\"Python\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743e9f1-a42a-4ef4-b9de-ebc98b70a807",
   "metadata": {},
   "source": [
    "## Introducción a las Redes Neuronales\n",
    "\n",
    "### ¿Qué es una neurona artificial?\n",
    "Su estructura y funcionamiento se inspiran en las neuronas biológicas. Las neuronas artificiales al igual que como sucede a nivel biógico reciben un estimulo del exterior, procesan esta señal para luego emitir una salida que transmiten al exterior o a otra neurona.\n",
    "\n",
    "Una neurona artificial o perceptrón se compone de los siguientes elementos:\n",
    "- x<sub>i</sub> representa la i-esima entrada.\n",
    "- w<sub>ij</sub> representan unos parámetros llamados pesos que controlan el nivel de inhibicion o excitación de las neuronas.\n",
    "- b<sub>j</sub> representan otros parámetros llamados sesgos (en inglés, bias)\n",
    "- z, es la suma de los estímulos recibidos por la neurona\n",
    "- f(z) es la función de activación o transferencia\n",
    "- y<sub>i</sub> corresponde con la salida generada por la neurona\n",
    "  \n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td><img src=\"images/neurona.jpg\" alt=\"IBM\" width=\"350\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br><br>\n",
    "\n",
    "### ¿Qué es una red neuronal?\n",
    "Una red neuronal es un modelo computacional que se inspira en el funcionamiento del cerebro humano. Está formada por nodos que simulan neuronas y se organizan en capas. En la capa de entrada se reciben las características de entrada (x), donde cada nodo (neurona artificial) representa una de estas características y procesa la información que recibe para transmitirla a las capas siguientes.\n",
    "\n",
    "Funcionamiento de una neurona:\n",
    "\n",
    "**Recibe entrada:**\n",
    "- Las entradas a una neurona pueden ser datos como píxeles de una imagen o características de un conjunto de datos.\n",
    "- Estas entradas vienen con ciertos pesos, que son valores numéricos que ajustan la importancia de cada entrada.\n",
    "    \n",
    "**Calcular la suma ponderada:**\n",
    "- La neurona calcula una suma ponderada de las entradas. Esto significa que cada entrada se multiplica por su peso correspondiente y luego se suman todos esos valores.\n",
    "- También se añade un sesgo (bias), que es un valor adicional que permite a la neurona ajustar la salida con más precisión.\n",
    "\n",
    "**Aplicar la función de activación:**\n",
    "- La suma ponderada se pasa a través de una función de activación. Esta función introduce no linealidad, permitiendo que la red aprenda relaciones complejas entre las entradas y salidas.\n",
    "\n",
    "***Genera la salida:***\n",
    "- La salida de la función de activación se convierte en la entrada para las neuronas en la siguiente capa, o en el resultado final si estamos en la última capa.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c627f-65ac-4d7b-90d4-5cc5e04c0095",
   "metadata": {},
   "source": [
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td><img src=\"images/redneuronal.png\" alt=\"redneuronal\" width=\"350\" height=\"200\"> </td>\n",
    "        <br>\n",
    "    </tr>\n",
    "</table>\n",
    "    <div style=\"text-align: center;\">\n",
    "    <a href=\"https://es.wikipedia.org/wiki/Red_neuronal_artificial\">Fuente de la imagen Wikipedia.</a></div>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84908e24-bd26-45ef-a85a-a23b563a272e",
   "metadata": {},
   "source": [
    "Es importante notar que el número de capas determina la profundidad de la red. Las redes neuronales con más de dos capas se consideran profundas y se conocen como redes de **Deep Learning** (Aprendizaje Profundo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21f797-700a-4a88-8a10-e13b02fd5bf9",
   "metadata": {},
   "source": [
    "#### ¿Qué son los pesos?\n",
    "Los pesos representan las conexiones entre las neuronas y pueden amplificar o atenuar las señales. Son elementos internos de la red neuronal que influyen en sus resultados. Durante el entrenamiento, es importante encontrar los valores óptimos de los pesos para que la red funcione correctamente. Los pesos suelen representarse con la letra \"W\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382c46e-cf69-454a-a267-2f99b27c3069",
   "metadata": {},
   "source": [
    "#### ¿Qué son los sesgos?\n",
    "Los sesgos en una red neuronal son valores adicionales que se suman a las entradas. Estos valores también tienen un peso, igual que las conexiones entre neuronas. Se añaden sesgos en la capa de entrada y en cada capa oculta para ayudar a que la red funcione mejor, incluso cuando algunas entradas son cero. Los sesgos se representan con la letra \"b\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17618fa2-1dcc-49d6-ab66-3400ae0fea9a",
   "metadata": {},
   "source": [
    "#### ¿Qué son las funciones de activacion?\n",
    "La salida de una neurona en una red neuronal se determina mediante las funciones de activación. Estas funciones introducen procesamiento no lineal, lo que permite a la red neuronal aprender y modelar relaciones complejas en los datos. La función de activación actúa como una puerta, decidiendo si la señal recibida por la neurona es lo suficientemente fuerte como para pasar a la siguiente capa de la red. \n",
    "\n",
    "Las funciones de activacion más usadas son:\n",
    "- **La unidad rectificadora lineal (RELU):** ReLU permite solo valores positivos y convierte valores negativos a cero. Es muy popular en redes neuronales profundas debido a su simplicidad y eficiencia computacional, y se utiliza principalmente para evitar el problema del desvanecimiento del gradiente.\n",
    "\n",
    "- **La funcion sigmoide (logística):** La función sigmoide produce salidas entre 0 y 1, lo que la hace útil para problemas de clasificación binaria y para introducir no linealidad en la red. Sin embargo, puede sufrir del problema del desvanecimiento del gradiente.\n",
    "\n",
    "- **Tangente hiperbólica (Tanh):** La función tanh produce salidas entre -1 y 1, centrando los datos alrededor de cero. Esto puede mejorar la convergencia durante el entrenamiento de redes neuronales, aunque también puede sufrir del problema del desvanecimiento del gradiente.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa492fe4-4c6e-4166-9b81-f3c0d0049320",
   "metadata": {},
   "source": [
    "Ejemplo sencillo de lo que hace una neurona:\n",
    "\n",
    "1. Recibir el dato de entrada: 3\n",
    "2. Multiplicar por el peso: 3 * 2 = 6\n",
    "3. Sumar el sesgo: 6 + 1 = 7\n",
    "4. Aplicar la función de activación:\n",
    "    - Con ReLU(7)=7\n",
    "    - Con Sigmoid ≈ 0.9991\n",
    "5. Generar la salida:\n",
    "    - Con ReLU: 7\n",
    "    - Con Sigmoid: 0.9991"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63faf86a-9318-4f8c-b6b4-243c3d20d37e",
   "metadata": {},
   "source": [
    "#### ¿Cómo se entrena una red neuronal?\n",
    "Entrenar una red neuronal implica dos fases principales. Primero, en forward propagation, los datos de entrada se mueven a través de la red, pasando por cada capa. En cada neurona, se multiplica el dato por un peso, se suma un sesgo y se aplica una función de activación para obtener una salida. Esto continúa hasta que la red produce una predicción. Luego, en backpropagation, se compara esta predicción con el valor real para calcular el error. Este error se envía de vuelta a través de la red, ajustando los pesos y sesgos para mejorar las predicciones. Este ciclo se repite muchas veces para que la red aprenda y reduzca el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4dd1f8-75e2-4f9a-a80b-fcb98f8c71cf",
   "metadata": {},
   "source": [
    "### Tipos de redes neuronales más populares:\n",
    "\n",
    "- **Perceptrón (Perceptron):**\n",
    "    - Es la forma más simple de una red neuronal, compuesta por una sola neurona.\n",
    "    - Se utiliza principalmente para problemas de clasificación binaria.\n",
    "    <br></br>\n",
    "- **Redes Neuronales de Capa Densa (Feedforward Neural Networks):**\n",
    "    - Estas redes consisten en capas de neuronas donde cada neurona de una capa está conectada a todas las neuronas de la siguiente capa.\n",
    "    - Son adecuadas para una variedad de tareas de clasificación y regresión.\n",
    "    <br></br>\n",
    "- **Redes Neuronales Convolucionales (Convolutional Neural Networks, CNNs):**\n",
    "    - Están diseñadas para procesar datos con una estructura de rejilla, como imágenes.\n",
    "    - Utilizan convoluciones para detectar patrones y características en los datos.\n",
    "    <br></br>\n",
    "- **Redes Neuronales Recurrentes (Recurrent Neural Networks, RNNs):**\n",
    "    - Están diseñadas para trabajar con datos secuenciales, como series temporales o texto.\n",
    "    - Utilizan bucles para mantener un estado interno que puede recordar información de pasos anteriores.\n",
    "     <br></br>\n",
    "- **Redes Neuronales de Transformadores (Transformers):**\n",
    "    - Son arquitecturas diseñadas para manejar secuencias de datos de manera más eficiente que las RNNs.\n",
    "    - Son muy populares en tareas de procesamiento del lenguaje natural (NLP), como la traducción automática y el análisis de texto.\n",
    "    <br></br>\n",
    "- **Redes Neuronales Adversarias (Generative Adversarial Networks, GANs):**\n",
    "    - Consisten en dos redes neuronales que compiten entre sí: un generador y un discriminador.\n",
    "    - El generador crea datos falsos, mientras que el discriminador trata de distinguir entre datos reales y falsos.\n",
    "    - Utilizadas para la generación de imágenes, mejora de resolución de imágenes, transferencia de estilo y generación de datos sintéticos.\n",
    "  <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec98a0e-da71-4675-beef-7dcffd80d02c",
   "metadata": {},
   "source": [
    "### Redes Neuronales Adversarias (GANs)\n",
    "¿Qué son las Redes Neuronales Adversarias (GANs)?\n",
    "\n",
    "Las Redes Neuronales Adversarias, o GANs por sus siglas en inglés, son un tipo de red neuronal especial en la que dos modelos (o redes) compiten entre sí en un proceso de aprendizaje. Esta competencia ayuda a ambos modelos a mejorar continuamente. Las GANs fueron introducidas por Ian Goodfellow en 2014.\n",
    "\n",
    "\n",
    "#### Componentes de las GANs\n",
    "- **Generador (Generator):**\n",
    "    - El generador crea datos falsos (como imágenes falsas) a partir de un ruido aleatorio.\n",
    "    - Su objetivo es hacer estos datos falsos tan realistas que el discriminador no pueda distinguirlos de los datos reales.\n",
    "    - Imagina al generador como un falsificador de billetes. Este falsificador comienza con un billete en blanco (o en términos técnicos, un vector de ruido aleatorio) y trata de crear un billete que parezca real.\n",
    "    - El objetivo del generador es engañar al discriminador, haciendo que sus billetes falsos sean tan convincentes que el discriminador piense que son reales.\n",
    "    <br></br>\n",
    "- **Discriminador (Discriminator):**\n",
    "    - El discriminador recibe tanto datos reales (del conjunto de datos de entrenamiento) como datos falsos (del generador).\n",
    "    - Su objetivo es distinguir correctamente entre los datos reales y los datos falsos.\n",
    "    - Piensa en el discriminador como un policía. Su trabajo es examinar los billetes y decidir si son reales (billetes genuinos) o falsos (billetes creados por el generador).\n",
    "    - El discriminador recibe tanto billetes reales del conjunto de datos de entrenamiento como billetes falsos del generador. Su objetivo es identificar correctamente cuáles son reales y cuáles son falsos.\n",
    "    <br></br>\n",
    "\n",
    "#### Cómo funcionan las GANs\n",
    "\n",
    "1. **Inicialización:**\n",
    "    - Las dos redes, generador y discriminador, se inician con pesos aleatorios.\n",
    "    <br></br>\n",
    "2. **Entrenamiento del discriminador:**\n",
    "    - Se le dan al discriminador algunos datos reales y algunos datos falsos generados por el generador.\n",
    "    - El discriminador aprende a diferenciar entre los datos reales y los falsos.\n",
    "    <br></br>\n",
    "4. **Entrenamiento del generador:**\n",
    "    - El generador usa el feedback del discriminador para mejorar. Intenta crear datos falsos que el discriminador no pueda identificar como falsos.\n",
    "    <br></br>\n",
    "5. **Ciclo de competencia:**\n",
    "- Este proceso se repite muchas veces. El generador y el discriminador se vuelven cada vez mejores en sus tareas respectivas: el generador en crear billetes realistas y el discriminador en identificar billetes falsos.\n",
    "- Se busca que el generador y el discriminador logren el equilibrio perfecto, es decir, que los billetes falsos sean tan convincentes que el discriminador apenas pueda distinguirlos de los billetes reales.\n",
    "    <br></br>\n",
    "**Aplicaciones de las GANs en imágen**\n",
    "- Crear imágenes realistas, como rostros de personas que no existen.\n",
    "- Mejora de imágenes: Aumentar la resolución de imágenes borrosas.\n",
    "- Transferencia de estilo: Cambiar el estilo de una imagen para que parezca una pintura famosa.\n",
    "- Generación de datos sintéticos: Crear datos para entrenar otros modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edca5e2-90ef-4546-b387-e0ab79bacc97",
   "metadata": {},
   "source": [
    "#### Funcionamiento de este tipo de redes\n",
    "<body>\n",
    "    <table align=\"center\">\n",
    "        <tr>\n",
    "            <td><img src=\"images/gans.png\" alt=\"GANs Image 1\" width=\"350\"></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"images/gans2.png\" alt=\"GANs Image 2\" width=\"350\"></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <br><br>\n",
    "    <footer>\n",
    "        <p style=\"text-align: center; font-size: 12px;\">\n",
    "            Algunas imágenes utilizadas en este curso son cortesía de <a href=\"https://www.tensorflow.org\">TensorFlow</a>, utilizadas bajo la \n",
    "            <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">Licencia Apache 2.0</a>.\n",
    "        </p>\n",
    "    </footer>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd001f7-ebe0-43dd-9bbf-70ea5909bbc1",
   "metadata": {},
   "source": [
    "### Práctica 1: \n",
    "Implementación de un modelo generativo básico, tal como un codificador automático variable (VAE) o una red generativa adversarial (GAN). En este caso vamos a elegir crear una red generativa adversarial (GAN) ya que es más interesante por los conceptos que involucra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c032ad-1dfc-4c49-84bc-be2814a61f03",
   "metadata": {},
   "source": [
    "#### Implementación de una GAN\n",
    "Usaremos un ejemplo de red adversaria para reconocimiento de texto y el dataset que podemos ver debajo MNIST. Este dataset es el \"Hello World\" de la visión artificial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf215ae-3a69-4224-91be-7e71ff56255a",
   "metadata": {},
   "source": [
    " <table align=\"center\">\n",
    "        <tr>\n",
    "            <td><img src=\"images/mnist.png\" alt=\"GANs Image 1\" width=\"350\"></td>\n",
    "        </tr>\n",
    " </table>\n",
    " <br><br>\n",
    "    <footer>\n",
    "        <p style=\"text-align: center; font-size: 12px;\">\n",
    "            Algunas imágenes utilizadas en este curso son cortesía de <a href=\"https://es.wikipedia.org/wiki/Base_de_datos_MNIST#/media/Archivo:MnistExamplesModified.png\">Wikipedia</a>\n",
    "        </p>\n",
    "    </footer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84881653-a39b-4006-a571-a516741edf0c",
   "metadata": {},
   "source": [
    "**Paso 1:** Importar librerías y configurar parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7d5229-c1f5-4879-ab5a-7003dc8f6b61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Configurar parámetros iniciales\n",
    "BUFFER_SIZE = 60000  # Tamaño del buffer para el conjunto de datos\n",
    "BATCH_SIZE = 256  # Tamaño del lote para el entrenamiento\n",
    "EPOCHS = 100  # Número de épocas para entrenar\n",
    "noise_dim = 100  # Dimensión del ruido para el generador\n",
    "num_examples_to_generate = 16  # Número de ejemplos a generar\n",
    "\n",
    "# Usar el mismo vector semilla para generar imágenes a lo largo del tiempo\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab467c-6402-40c1-bd82-0795af062df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20070953-d4a6-419f-b0ee-ee37fece9fd7",
   "metadata": {},
   "source": [
    "**Paso 2:** Cargar y preprocesar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e229700-69cf-43db-821c-8bbe5627ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de MNIST y preprocesarlo\n",
    "(train_images, train_labels), (_, _) = mnist.load_data()\n",
    "\n",
    "# Normalizar las imágenes al rango [-1, 1] y aplanarlas\n",
    "train_images = (train_images.reshape(train_images.shape[0], 784).astype('float32') - 127.5) / 127.5\n",
    "\n",
    "# Crear un objeto Dataset de TensorFlow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b30eb7-deb5-4160-a844-fb5e71b4d720",
   "metadata": {},
   "source": [
    "**Paso 3:** Definimos el modelo de generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b74c4-c396-4549-bf09-26568a257059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_shape=(noise_dim,)))  # Capa densa con 256 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dense(512))  # Capa densa con 512 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dense(1024))  # Capa densa con 1024 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dense(784, activation='tanh'))  # Capa de salida con activación 'tanh' para generar valores en el rango [-1, 1]\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()  # Crear el modelo del generador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68d948-3ea0-439a-9d09-882dc9dbc083",
   "metadata": {},
   "source": [
    "**Paso 4:** Definimos el modelo de discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0d636-efdb-4a4c-aea0-ff0a53f6c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(1024, input_shape=(784,)))  # Capa densa con 1024 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dropout(0.3))  # Dropout para evitar sobreajuste\n",
    "    model.add(layers.Dense(512))  # Capa densa con 512 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dropout(0.3))  # Dropout para evitar sobreajuste\n",
    "    model.add(layers.Dense(256))  # Capa densa con 256 unidades\n",
    "    model.add(layers.LeakyReLU())  # Activación LeakyReLU\n",
    "    model.add(layers.Dropout(0.3))  # Dropout para evitar sobreajuste\n",
    "    model.add(layers.Dense(1))  # Capa de salida para la clasificación\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()  # Crear el modelo del discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe730a-d279-482d-9590-9e75450f45f1",
   "metadata": {},
   "source": [
    "**Paso 5:** Definimos las funciones de pérdida y los optimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbe243-ff37-4a1b-bb13-919e41f65dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)  # Pérdida para las imágenes reales\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)  # Pérdida para las imágenes falsas\n",
    "    total_loss = real_loss + fake_loss  # Pérdida total\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)  # Pérdida del generador\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f996a66-5ce7-4ec1-8c13-77c5e5c5dca7",
   "metadata": {},
   "source": [
    "**Paso 6:** Definir el bucle de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5d142-7182-4568-82ad-8bcc73fdfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])  # Generar ruido aleatorio\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)  # Generar imágenes\n",
    "\n",
    "        real_output = discriminator(images, training=True)  # Evaluar imágenes reales\n",
    "        fake_output = discriminator(generated_images, training=True)  # Evaluar imágenes generadas\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)  # Calcular pérdida del generador\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)  # Calcular pérdida del discriminador\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)  # Calcular gradientes del generador\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)  # Calcular gradientes del discriminador\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))  # Aplicar gradientes al generador\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))  # Aplicar gradientes al discriminador\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)  # Entrenar un lote\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)  # Generar y guardar imágenes\n",
    "\n",
    "        print(f'Tiempo para la época {epoch + 1} es {time.time() - start} segundos')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)  # Generar y guardar imágenes finales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24f230-9436-4358-bc15-33626b1d4a17",
   "metadata": {},
   "source": [
    "**Paso 7:** Función para generar y guardar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e0219-8f8a-4f50-a344-54a60afdd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)  # Generar imágenes a partir del ruido\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(tf.reshape(predictions[i], (28, 28)) * 127.5 + 127.5, cmap='gray')  # Mostrar la imagen\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('samples/image_at_epoch_{:04d}.png'.format(epoch))  # Guardar la imagen\n",
    "    plt.show()  # Mostrar la figura\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbead94-3bfa-48b4-9c90-efdcce92e78c",
   "metadata": {},
   "source": [
    "**Paso 8:** Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700ee07-af00-49d6-a8df-2c861dff3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)  # Iniciar el entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb423b6-86c8-445e-85c0-6573de149ed7",
   "metadata": {},
   "source": [
    "## Entender modelos grades de lenguaje preentrenados y adaptación a tareas específicas de NLP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4dd1d-0dcc-4044-8cb9-e2c1efee91d8",
   "metadata": {},
   "source": [
    "### Práctica 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3f2e5-f8b2-4a31-927c-702c24ea5a6d",
   "metadata": {},
   "source": [
    "#### Exploración de modelos preentrenados, tales como BERT o GPT, y su adaptación a tareas específicas de NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ea082-ba85-4633-a34b-f11fd0692d2b",
   "metadata": {},
   "source": [
    "En esta práctica, exploraremos cómo utilizar modelos de lenguaje preentrenados, específicamente GPT (Generative Pretrained Transformer), para tareas de Procesamiento de Lenguaje Natural (NLP). GPT es un modelo desarrollado por OpenAI que ha sido preentrenado en una gran cantidad de datos de texto y puede ser adaptado para diversas tareas de NLP sin necesidad de entrenamiento adicional.\n",
    "\n",
    "\n",
    "**Ejemplo:**\n",
    "- Clasificación de sentimientos con GPT: vamos a usar GPT para clasificar si un texto tiene un sentimiento positivo o negativo.\n",
    "\n",
    "**Objetivos**\n",
    "- Comprender el uso de modelos preentrenados para NLP.\n",
    "- Adaptar un modelo GPT para una tarea específica de análisis de sentimiento.\n",
    "- Implementar y ejecutar consultas usando GPT para obtener respuestas basadas en entradas de texto en español."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827b207-2c67-4630-a99e-34177bba5485",
   "metadata": {},
   "source": [
    "### MODELO GPT\n",
    "Se un modelo de IA que ya ha sido preentrenado para realizar tareas específicas sin realizar ajustes adicionales en el modelo.Enviamos consultas a un modelo GPT-3.5-turbo de OpenAI para obtener respuestas sobre el sentimiento de ciertas frases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc23343-594d-4062-94e3-ecc0f22c2515",
   "metadata": {},
   "source": [
    "**Paso 1:** Instalación de la Biblioteca OpenAi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d09e21-d5bb-4f4f-b2f8-18a6a9572093",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbdcf8-81ea-4b8f-aa2a-8385e5c4c066",
   "metadata": {},
   "source": [
    "**Paso 2:** Configuración de la Clave API\n",
    "\n",
    "- Configurar clave API de OpenAI en el script de Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fe86b458-2109-4526-ab8f-c70a5021ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# Reemplaza 'TU_CLAVE_API' con tu clave API de OpenAI\n",
    "OPENAI_API_KEY = 'TU_CLAVE_API'\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dc5616-0bf2-4afc-be94-f2463e8413a7",
   "metadata": {},
   "source": [
    "**Paso 3:** Definición de Funciones para Utilizar GPT\n",
    "- Definimos una función para enviar consultas al modelo GPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8a03bb12-1932-4ad4-9a13-410faaddaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_respuesta(prompt, model=\"gpt-3.5-turbo\"):\n",
    "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "  response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=messages,\n",
    "  max_tokens=4000, # número máximo de tokens de entrada\n",
    "  temperature=0.7, #ajustamos el nivel de aleatoriedad de la respuesta\n",
    "  )\n",
    "  return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af9401-a4e3-4d88-8f91-4b668033bfce",
   "metadata": {},
   "source": [
    "**Paso 4:** Ejemplo de uso del modelo GPT\n",
    "- Utilizamos la función anterior para generar respuestas a partir de un conjunto de textos en español:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "221d919a-d1d4-4162-bd74-4e19cf362b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Me encanta este producto - Respuesta del modelo: El sentimiento de la frase es positivo, de gusto y satisfacción.\n",
      "Texto: Odio esto - Respuesta del modelo: El sentimiento de la frase es de disgusto o aversión. La persona que la dice claramente no está contenta con la situación o circunstancia a la que se refiere.\n",
      "Texto: Es maravilloso - Respuesta del modelo: El sentimiento de la frase \"Es maravilloso\" es de alegría, admiración y satisfacción. Indica que algo es excelente o excepcionalmente bueno.\n",
      "Texto: Esto es terrible - Respuesta del modelo: El sentimiento de la frase \"Esto es terrible\" es de tristeza, preocupación o desesperación. La persona que lo dice está expresando su disgusto o malestar ante una situación que considera negativa o desagradable.\n"
     ]
    }
   ],
   "source": [
    "# Frases de prueba en español\n",
    "textos_prueba = [\n",
    "    \"Me encanta este producto\",\n",
    "    \"Odio esto\",\n",
    "    \"Es maravilloso\",\n",
    "    \"Esto es terrible\"\n",
    "]\n",
    "\n",
    "# Generar respuestas para cada texto de prueba\n",
    "for texto in textos_prueba:\n",
    "    prompt = f\"¿Cuál es el sentimiento de la siguiente frase? '{texto}'\"\n",
    "    respuesta = obtener_respuesta(prompt)\n",
    "    print(f\"Texto: {texto} - Respuesta del modelo: {respuesta}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b142258-fc13-430a-b28a-949061b0f340",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7797d-b749-4cb8-b908-5b2522a8b318",
   "metadata": {},
   "source": [
    "### MODELO BERT\n",
    "Ejemplo de fine tuning con un modelo BERT. En este ejemplo, estamos ajustando un modelo BERT preentrenado para la tarea específica de clasificación de texto en dos categorías (positivo y negativo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b8649-6b2d-4225-a75c-2b1c5c67a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Definir la clase del conjunto de datos\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Método para obtener la longitud del conjunto de datos\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    # Método para obtener un elemento del conjunto de datos\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=self.max_length, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        return encoding\n",
    "\n",
    "# Inicializar el tokenizador y el modelo preentrenado\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Definir los datos de entrenamiento y validación\n",
    "texts = [\"I love this!\", \"This is bad.\", \"Amazing product!\", \"Not good.\", \"I like it\", \"I hate it\"]\n",
    "labels = [1, 0, 1, 0, 1, 0]\n",
    "train_texts, val_texts = texts[:4], texts[4:]\n",
    "train_labels, val_labels = labels[:4], labels[4:]\n",
    "\n",
    "# Crear instancias del conjunto de datos\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer, max_length=16)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer, max_length=16)\n",
    "\n",
    "# Configurar los argumentos del entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # Directorio para guardar los resultados\n",
    "    num_train_epochs=3,  # Número de épocas de entrenamiento\n",
    "    per_device_train_batch_size=2,  # Tamaño del lote de entrenamiento por dispositivo\n",
    "    per_device_eval_batch_size=2,  # Tamaño del lote de evaluación por dispositivo\n",
    "    warmup_steps=500,  # Número de pasos de calentamiento\n",
    "    weight_decay=0.01,  # Decaimiento de peso\n",
    "    logging_dir='./logs',  # Directorio para guardar los registros\n",
    "    logging_steps=10,  # Número de pasos entre registros\n",
    "    load_best_model_at_end=True,  # Cargar el mejor modelo al final del entrenamiento\n",
    "    evaluation_strategy=\"epoch\",  # Evaluar al final de cada época\n",
    "    save_strategy=\"epoch\"  # Guardar el modelo al final de cada época\n",
    ")\n",
    "\n",
    "# Crear el entrenador\n",
    "trainer = Trainer(\n",
    "    model=model,  # Modelo a entrenar\n",
    "    args=training_args,  # Argumentos de entrenamiento\n",
    "    train_dataset=train_dataset,  # Conjunto de datos de entrenamiento\n",
    "    eval_dataset=val_dataset  # Conjunto de datos de evaluación\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d6a27-c9bc-4894-9b5f-8af326350019",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
